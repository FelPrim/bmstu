[[Зубарев Кирилл Михайлович]]
Что-то: https://youtu.be/y4pYFzQ8K_0
Консультация в четверг с 12 до 3

Критерий Вальда
Отношение правдоподобия:
$$\frac{L(x_{n},\Theta_{0})}{L(x_{n},\Theta_{1})}=z(\vec{x}_{n},n)$$
$H_0$: $\Theta=\Theta_{0}$
$H_1$: $\Theta=\Theta_{1}$
$\alpha, \beta$ - ошибки первого и второго порядка
$$\begin{gather}
B=\frac{\beta}{1-\alpha}, A=\frac{1-\beta}{\alpha} 
\end{gather}$$
$\nu=\min{\left. x \right\rvert z(x_{n})\not\in(A,B))}$ 
$M\nu<\infty$

Что если мы хотим посчитать среднее число испытаний до принятия решения?
$$\begin{gather}
M\nu \\
M_{\Theta_{0}}\nu - \text{среднее время до принятия }H_{0} \\
M_{\Theta_{1}}\nu - \text{до принятия }H_{1}
\end{gather}$$
Введём $Z(x_{n})=\ln z(x_{n})$
Функция правдоподобия - произведение
$$\begin{gather}
Z(x_{n})=\ln\left( \frac{\prod_{k=1}^n P(x_{k},\Theta_{1})}{\prod _{k=1}^n P(x_{k},\Theta_{0})} \right) \\
Z(x_{n})=\sum_{k=1}^{n} y_{k} \\
MZ(x_{\nu})=M\sum_{k=1}^{\nu} y_{k}\equiv \equiv M\nu\cdot My_{k} \\
M\nu=\frac{MZ(x_{\nu})}{My_{k}} \\
Z(x_{\nu})=\ln(z(x_{\nu}))
\end{gather}$$

Если верна $H_{0}$

| $\ln A$  | $\ln B$    |
| -------- | ---------- |
| $\alpha$ | $1-\alpha$ |
$$\begin{gather}
M_{\Theta_{0}}\nu=\frac{\alpha \ln A+(1-\alpha)\ln B}{My_{k}}
\end{gather}$$
Если верна $H_{1}$


| $\ln A$   | $\ln B$ |
| --------- | ------- |
| $1-\beta$ | $\beta$ |
$$\begin{gather}
M_{\Theta_{1}}\nu=\frac{(1-\beta)\ln A+\beta \ln B}{My_{k}}
\end{gather}$$
дисперсия $\nu$?
$$x_{1},x_{2},\ldots,x_{n}-E(\lambda)$$
$$\begin{gather}
H_{0}: \ \lambda=\lambda_{0}=\frac{1}{3} \\
H_{1}: \ \lambda=\lambda_{1}=\frac{5}{11} 
\end{gather}$$
Найдём $M_{\lambda_{0}}\nu, M_{\lambda_{1}}\nu$
Для простых гипотез выполняется какое-то свойство

$$\begin{gather}
\alpha=\beta=0.05 \\
A=\frac{\alpha}{1-\beta}=19 \\
B=\frac{1}{19} \\
y_{k}=\ln\left( \frac{P(x_{k},\lambda_{1})}{P(x_{k},\lambda_{0})} \right)=\ln\left( \frac{\lambda_{1}e^{-\lambda_{1}x_{k}}}{\lambda_{0}e^{-\lambda_{0}x_{k}} }\right)=\ln\left( \frac{\lambda_{1}}{\lambda_{0}} \right)+(\lambda_{0}-\lambda_{1})x_{k} \\
\text{Если }H_{0} \text{ верна: }M_{\lambda_{0}}y_{k}=\ln\left( \frac{\lambda_{1}}{\lambda_{0}} \right)+(\lambda_{0}-\lambda_{1})\cdot \frac{1}{\lambda_{0}} \\
M_{\lambda_{0}}\nu=\frac{0.05\cdot \ln19 +0.95\cdot \ln\left( \frac{1}{19} \right) }{\ln\left( \frac{\lambda_{1}}{\lambda_{0}}+(\lambda_{0}-\lambda_{1}) \frac{1}{\lambda_{0}} \right)}=49.55 \\
\text{Если верна }H_{1}: \\
M_{\lambda_{1}}y_{k}=M_{\lambda_{1}}\left( \ln\left( \frac{\lambda_{1}}{\lambda_{0}} \right)+(\lambda_{0}-\lambda_{1})x_{k} \right)=\ldots=\ln \frac{\lambda_{1}}{\lambda_{0}} +(\lambda_{0}-\lambda_{1}) \frac{1}{\lambda_{1}} \\
M_{\lambda_{1}}\nu=\frac{0.95\cdot \ln19 + 0.05\cdot \ln\left( \frac{1}{19} \right)}{\ln\left( \frac{\lambda_{1}}{\lambda_{0}}+(\lambda_{0}-\lambda_{1}) \frac{1}{\lambda_{1}} \right)}=60.9
\end{gather}$$




МЕТОД МОМЕНТОВ:
$M\xi=\vec{x}\Rightarrow \vec{p}=\vec{x}$
произведение вероятностей получить данный элемент выборки - L


Найти среднее число испытаний до принятия решения о значении параметра $p$ из распределения Бернулли.
$\alpha=0.01, \beta=0.05$
$H_{0}:\ P=P_{0}=0.1$
$H_{1}: \ P=P_{1}=0.2$
$$\begin{gather}
P(\xi=j)=p^j(1-p)^{1-j} \\
M\xi=p
\end{gather}$$
1\. Критерий Неймана Пирсона
$$\begin{gather}
\frac{L(x_{n},P_{1})}{L(x_{n},P_{0})}>C \ (H_{0} \text{ отвергается}) \\
\frac{L(x_{n},P_{1})}{L(x_{n},P_{0})}=\frac{\prod_{k=1}^n P (\xi_{k}=x_{k},P_{1})}{\prod _{k=1}^n P(\xi_{k}=x_{k},P_{0})}=\frac{\prod _{k=1}^n p_{1}^{x_{k}}(1-p_{1})^{1-x_{k}}}{\prod _{k=1}^n p_{0}^{x_{k}}(1-p_{0})^{1-x_{k}}} > C 
\end{gather}$$
Преобразуем относительно достаточной статистики
$$\begin{gather}
\left( \frac{p_{1}}{p_{0}} \right)^{\sum x_{k}}\cdot \left( \frac{1-p_{1}}{1-p_{0}} \right)^{\sum (1-x_{k})}=\left( \frac{p_{1}}{p_{0}} \right)^{\sum x_{k}}\left( \frac{1-p_{1}}{1-p_{0}} \right)^{-\sum x_{k}}\left( \frac{1-p_{1}}{1-p_{0}} \right)^n= \\
=\left( \frac{p_{1}(1-p_{0})}{p_{0}(1-p_{1})} \right)^{\sum x_{k}}\left( \frac{1-p_{1}}{1-p_{0}} \right)^n>C \\
\sum x_{k} \cdot \ln\left( \frac{p_{1}(1-p_{0})}{p_{0}(1-p_{1})} \right)+n\ln\left(\frac{1-p_{1}}{1-p_{0}}\right) >\ln C \\
\sum x_{k} > \frac{\ln C-n\ln\left(\frac{1-p_{1}}{1-p_{0}}\right)}{\ln\left( \frac{p_{1}(1-p_{0})}{p_{0}(1-p_{1})} \right)}=C'
\end{gather}$$
Вид критического множества ($H_{0}$ отверг):
$S:\vec{x}>C'$
$\alpha =P(\vec{x}>C' \vert H_{0})$
Центральная предельная теорема?
$$\begin{gather}
\begin{vmatrix}
\vec{x}\sim N\left( P (aka(MX_{k})), \sqrt{ \frac{p(1-p)}{n} } \left( aka\left( \sqrt{ \frac{\Delta x_{k}}{n} } \right) \right) \right) \\
\frac{\vec{x}-P}{\sqrt{ p(1-p) }}\sqrt{ n }\sim N(0,1)
\end{vmatrix} \\ 
1-\alpha=P(\vec{x}<C'\vert H_{0})=P\left( \frac{\vec{x}-p_{0}}{\sqrt{ p_{0}(1-p_{0}) }}\sqrt{ n }< \frac{C'-p_{0}}{\sqrt{ p_{0}(1-p_{0}) }}\sqrt{ n } \right) \\
\frac{C'-p_{0}}{\sqrt{ p_{0}(1-p_{0}) }}\sqrt{ n }=u_{1-\alpha} \\
u_{1-\alpha}-\text{квантиль} \\
\beta=P(\vec{x}<C'\vert H_{1})=P\left( \frac{\vec{x}-p_{0}}{\sqrt{ p_{0}(1-p_{0}) }}\sqrt{ n }< \frac{C'-p_{1}}{\sqrt{ p_{1}(1-p_{1}) }}\sqrt{ n } \right)  \\
\begin{cases}  \frac{C'-p_{1}}{\sqrt{ p_{1}(1-p_{1}) }}\sqrt{ n } =u_{\beta} \\
\frac{C'-p_{0}}{\sqrt{ p_{0}(1-p_{0}) }}\sqrt{ n }=u_{1-\alpha}  \end{cases} \Rightarrow \begin{cases} C'=0.151 \\
n=184 \end{cases} 
\end{gather}$$

2\. Критерий Вальда
$$\begin{gather}
\alpha=0.01,\beta=0.05 \\
A=\frac{1-\beta}{\alpha}=95,B=\frac{\beta}{1-\alpha}=\frac{5}{99} \\
y_{k}=\ln\left( \frac{P(\xi_{k}=x_{k},p_{1})}{P(\xi_{k}=x_{k},p_{0})} \right)=\ln\left( \frac{p_{1}^{x_{k}}(1-p_{1})^{1-x_{k}}}{p_{0}^{x_{k}}(1-p_{0})^{1-x_{k}}} \right)= \\
=\ln\left( \left( \frac{p_{1}}{p_{0}} \frac{1-p_{0}}{1-p_{1}} \right)^{x_{k}} \cdot \frac{1-p_{1}}{1-p_{0}}\right)= \\
=x_{k}\ln \frac{p_{1}}{p_{0}} \frac{1-p_{0}}{1-p_{1}} +\ln \frac{1-p_{1}}{1-p_{0}}
\end{gather}$$
Если верна $H_{0}:$
$$\begin{gather}
M_{p_{0}}\nu=\frac{0.01\ln 95 + 0.99 \ln \frac{5}{99}}{p_{0}\ln \frac{p_{1}}{p_{0}} \frac{1-p_{0}}{1-p_{1}}+\ln \frac{1-p_{1}}{1-p_{0}}}=80
\end{gather}$$
Если верна $H_{1}:$
$$\begin{gather}
M_{p_{1}}\nu=\frac{\beta \ln 95+ (1-\beta)\ln }{M=p_{1}, \text{ а не } p_{0}}=94
\end{gather}$$

16/12/2025
Рассматривали 2мерную выборку
$$\begin{gather}
(X_{1},Y_{1}),\ldots,(X_{n},Y_{n})
\end{gather}$$
Предполагаем, что выборка из нормального распределения
Выборочный коэффициент корреляции $r$
$$\begin{gather}
r=\frac{S_{XY}}{\sqrt{ S_{X} }\sqrt{ S_{Y} }}
\end{gather}$$
дисперсия на ковариации
$r=0:$
$$\begin{gather}
\frac{r}{\sqrt{ 1-r^2 }}\sqrt{ n-2 }\sim t(n-2)\text{ (закон распределения Стьюдента)} 
\end{gather}$$
$r\neq 0:$
$$\begin{gather}
\operatorname{ arth } (r)\sim N\left( a_{z}, \frac{1}{\sqrt{ n-3 }}  \right) \\
a_{z}=\operatorname{ arth } \left( r \right)+ \frac{r}{2(n-1)}
\end{gather}$$
Даны 2 2мерные нормальные выборки
$$\begin{gather}
n_{1}=28, r_{\text{в}1}=0.71 \\
n_{2}=39,r_{\text{в}2}=0.85 
\end{gather}$$
Проверить гипотезу, о том, что истинные коэффициенты корреляции равны
$$\begin{gather}
H_{0}:r_{1}=r_{2} \\
H_{1}:r_{1}\neq r_{2} \\
S:\lvert r_{\text{в}2}-r_{\text{в}1} \rvert >C\to \text{отвергаем} \\
S:\lvert \underbrace{ \operatorname{ arth } (r_{\text{в}2})-\operatorname{ arth } (r_{\text{в}1}) }_{ \xi } \rvert >C' \\
N\left( a_{z_{2}},\sqrt{ \frac{1}{n_{2}-3} } \right) ,N\left( a_{z_{1}},\sqrt{ \frac{1}{n_{1}-3} } \right) \\
\text{Разность нормальных законов - нормальнй закон} \\
M\xi=a_{z_{2}}-a_{z_{1}}=\cancel{ \operatorname{ arth } \left( r_{2}\right) }+\cancelto{ 0 }{ \frac{r_{2}}{2(n_{2}-1)} } -\cancel{ \operatorname{ arth } \left( r_{1} \right) }-\cancelto{ 0 }{ \frac{r_{1}}{2(n_{1}-1)} }=0 \\
D\xi-\eta=D\xi+D(-\eta)+2\operatorname{cov} (\xi-\eta) \\
D\xi=\frac{1}{ n_{2}-3 }+\frac{1}{ n_{1}-3 } \\
\xi\sim N\left(0,\sqrt{ \frac{1}{ n_{2}-3 }+\frac{1}{ n_{1}-3 } }\right) \\
\frac{\xi}{\sqrt{ \frac{1}{ n_{2}-3 }+\frac{1}{ n_{1}-3 } }}\sim N(0,1) \\
\alpha=0.01 \\
\alpha=P\left( \frac{\lvert \operatorname{ arth } r_{\text{в}2} -\operatorname{ arth } r_{\text{в}1}\rvert }{\sqrt{ \frac{1}{n_{1}-3} +\frac{1}{n_{2}-3}}} >C''  \vert H_{0}\right)
\end{gather}$$
$C''$ - квантиль уровня $\frac{\alpha}{2}$ (из графика нормального распределения видно)
$$S:\lvert \operatorname{ arth }r_{\text{в}2}-\operatorname{ arth }r_{\text{в}1} \rvert>u_{1-\frac{\alpha}{2}}\cdot \sqrt{ \frac{1}{n_{1}-3}+\frac{1}{n_{2}-3} }$$
0.369 и 0.67 -> $H_{0}$ принимается
б) При каких $r_{\text{в}2}$ разница будет не значима
$$\begin{gather}
\lvert \operatorname{ arth } r_{\text{в}1}-\operatorname{ arth } r_{\text{в}2}
 \rvert<0.67 \\
\operatorname{ arth } r_{\text{в}1}-0.67<\operatorname{ arth } r_{\text{в}2}<\operatorname{ arth } r_{\text{в}1}+0.67 \\
0.214 < r_{\text{в2}}<0.915
\end{gather}$$
Объём выборки очень маленький

Следующее занятие - РК
регрессия
С точки зрения теорвера
$$\begin{gather}
M(\eta\vert\xi)=f(\xi)+\varepsilon
\end{gather}$$
Производная Родона-Никодима
Линейная регрессия:
примеры:
$$\begin{gather}
y_{k}=\beta_{0}+\beta_{1}x_{k}+\varepsilon_{k} \\
\beta_{0},\beta_{1}:\sum \varepsilon_{k}^2=\min  \\
L=\sum (y_{k}-\beta_{0}-\beta_{1}x_{k})^2=\min 
\end{gather}$$
На практике:
решаем численными методами (градиентным спуском)
В теории:
$$\begin{gather}
\begin{cases}
\frac{ \partial L }{ \partial \beta_{0} } =2\sum_{k=1}^{n} (y_{k}-\beta_{0}-\beta_{1}x_{k})\cdot -1=0 \\
\frac{ \partial L }{ \partial \beta_{1} } =2\sum_{k=1}^{n} (y_{k}-\beta_{0}-\beta_{1}x_{k})\cdot -x_{k}=0
\end{cases} \\
\begin{cases}
\sum y_{k} & =\sum \beta_{0}  & +\sum \beta_{1}x_{k} \\
\sum y_{k}x_{k} & =\sum \beta_{0}x_{k} & +\sum \beta_{1}x_{k}^2
\end{cases} \\
\begin{cases}
n\beta_{0}+\beta_{1}\sum x_{k}=\sum y_{k} \\
\beta_{0} \sum x_{k}+\beta_{1}\sum x_{k}^2=\sum y_{k}x_{k}
\end{cases}
\end{gather}$$
$y_k$ - отклик, $x_{k}$ - ?
2 пример - тоже линейная регрессия
$y_{k}=\beta_{0}+\beta_{1}x_{k}+\beta_{2}x^2_{k}+\varepsilon_{k}$
3 пример - общий вид линейной регрессии
$$\begin{gather}
y_{k}=\sum_{j=0}^{m-1} \beta_{j}\cdot \psi_{j}(\vec{x}_{k})+\varepsilon_{k} \\
\psi_{j}-\text{базисные функции} \\
\vec{x}_{k}=\begin{pmatrix}
x_{k}^{(1)} \\
\ldots \\
x_{k}^{(p)}
\end{pmatrix}
\end{gather}$$
пример
$$\begin{gather}
y_{k}=\beta_{0}+\beta_{1}\sin(x_{k})+\beta_{2} \cos(x)+\varepsilon_{k} \\
\vec{\psi}=\begin{pmatrix}
1 \\
\sin x \\
\cos x
\end{pmatrix}
\end{gather}$$
В матричном виде
$$\begin{gather}
y=\begin{pmatrix}
y_{1} \\
y_{2} \\
\ldots \\
y_{n}
\end{pmatrix},\varepsilon=\begin{pmatrix}
\varepsilon_{1} \\
\varepsilon_{2} \\
\ldots \\
\varepsilon_{n}
\end{pmatrix},\beta=\begin{pmatrix}
\beta_{0} \\ \beta_{1} \\ \ldots \\ \beta_{m-1}
\end{pmatrix},F=\begin{pmatrix}
\psi_{0}(\vec{x}_{1}) & \psi_{1}(\vec{x}_{1}) & \ldots & \psi_{m-1}(\vec{x}_{1}) \\
\psi_{0}(\vec{x}_{2}) & \psi_{1}(\vec{x}_{2}) & \ldots & \psi_{m-1}(\vec{x}_{2}) \\
\ldots & \ldots & \ldots & \ldots \\
\psi_{0}(\vec{x}_{n}) & \psi_{1}(\vec{x}_{n}) & \ldots & \psi_{m-1}(\vec{x}_{n})
\end{pmatrix} \\
y=F\beta+\varepsilon
\end{gather}$$
$$\begin{gather}
\varepsilon=y-F\beta \\
\sum \varepsilon^2=\varepsilon^T\varepsilon=(y-F\beta)^T(y-F\beta) \\
\hat{\beta}=(F^TF)^{-1}F^Ty
\end{gather}$$


$$\begin{gather}
y_{k}=\beta_{0} +\beta_{1}\sin x_{k}+\beta_{2}e^{x_{k}} \\
\hat{\beta}=(F^TF)^{-1}F^Ty \\
\psi=\begin{pmatrix}
1 \\
\sin x \\
e^x
\end{pmatrix} \\
F=\begin{pmatrix}
1 & \sin(x_{1}) &  e^{x_{1}}\\
1 & \sin(x_{2}) &  e^{x_{2}}\\
\ldots & \ldots & \ldots \\
1 &  \sin(x_{n})& e^{x_{n}}
\end{pmatrix} \\
F^TF=\begin{pmatrix}
1 & 1 & \ldots & {1} \\
\sin x_{1} & \sin x_{2} & \ldots & \sin x_{n} \\
e^{x_{1}} & e^{x_{2}} & \ldots & e^{x_{n}}
\end{pmatrix}\begin{pmatrix}
1 & \sin(x_{1}) &  e^{x_{1}}\\
1 & \sin(x_{2}) &  e^{x_{2}}\\
\ldots & \ldots & \ldots \\
1 &  \sin(x_{n})& e^{x_{n}}
\end{pmatrix}= \\
=\begin{pmatrix}
n & \sum \sin x_{k} & \sum e^{x_{k}} \\
\sum \sin x_{k}  & \sum \sin^2x_{k} & \sum \sin x_{k}e^{x_{k}} \\
\sum e^{x_{k}}  &  \sum \sin x_{k}e^{x_{k}}& \sum e^{2x_{k}}
\end{pmatrix} 
\end{gather}$$


Консультация:
задачи, которые осталось сделать:
	посчитать остаточную дисперсию
	доверительный интервал для истинной остаточной дисперсии и ...
	элементы регрессионного анализа 



































