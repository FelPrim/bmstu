Теорвер и Матстат Севастьянова Бориса Николаевича (мат стат нет),
13/02/2025
Задача де Мере
Сколько раз нужно подбросить пару игральных костей, чтобы с вероятностью хотя бы $\frac{1}{2}$  выпало 6+6?
#### Колмогоровский подход
$(\Omega,\mathcal{A},P)$
$\Omega$ - множество элементарных исходов,
$\mathcal{A}$ - система подмножеств $\Omega$, является $\sigma$-алгеброй.
Элементы $\mathcal{A}$ - события.
$\omega\in \Omega$ - элементарный исход.
Если $\omega\in A$ - $\omega$ благоприятствует А
$\varnothing$ - невозможное событие.
$\Omega$ - достоверное событие
$A\subset B$ - событие А влечёт событие B
$A\backslash B$ - разность событий
$A+B=A \cup B$ - сумма собыьтий
$A\cdot B=A\cap B$

$P$ - мера на $\mathcal{A}$, из аксиоматики колмогорова:
1) $P(A)\geq 0$
2) $P(\Omega)=1$
3) $A\cap B=\varnothing \Rightarrow P(A+B)=P(A)+P(B)$ - A и B называются независимыми.
Примеры:
Классическая вероятностная модель:
$$\begin{gather}
\Omega\in X \ - \ \text{Конечное множество} \\
\mathcal{A}=2^X \ - \ \text{система всех подмножеств}\\
P(A\in \Omega)={\frac{|A|}{|\Omega|}}={\frac{\text{число благоприятных исходов}}{\text{Общее число исходов}}}
\end{gather}$$
Пример, поясняющий пример:
$$\begin{gather}
\Omega=\{ (i,j),\begin{matrix}
i=\overline{1,6}\\ 
j=\overline{1,6}
\end{matrix} \}
\end{gather}$$
Задача де Мере
n - подбрасываемая
$$\begin{gather}
\Omega=\{ (i_{1},j_{1}),(i_{2},j_{2}),\dots,(i_{36},j_{36}) \}\\
|\Omega|=36^n \\
A = \{ \text{Хотя бы 1 раз выпало 6+6} \} \\
\overline{A} = \Omega\backslash A \ - \ \text{Противоположное событие} \\
\Omega=\overline{A} + A \\
\overline{A}=\{ \text{Ни разу не выпало 6+6} \}\\
|\overline{A}|=35^n\\
1=P(\Omega)=P(A)+P(\overline{A})\\
P(\overline{A})=\left( \frac{35}{36} \right)^n\\
\left( \frac{35}{36} \right)^n<{\frac{1}{2}} \\
n \ln\left( \frac{35}{36} \right) < \ln\left( \frac{1}{2} \right) \\
n>\frac{\ln\left( \frac{1}{2} \right)}{\ln\left( \frac{35}{36} \right)} \approx 24,\dots
\end{gather}$$
#### Вычисление вероятностей в класс схеме - комбинаторная задача
Правила комбинаторики:
1) Правило суммы.
$$A\cap B=\varnothing\Rightarrow\#A\cup B=\#A+\#B$$
2) Правило произведения.
$$\#A\times B=\#A\cdot\#B$$
1. Перестановки в множестве с мощностью n:
$$P_{n}=n!$$
2. Размещения на m мест в множестве с мощностью n:
$$A_{n}^m=\frac{n!}{(n-m)!}$$
3. Сочетания из n элементов по m мест
$$C_{n}^m=\begin{pmatrix}
n \\
m
\end{pmatrix}={\frac{n!}{m!(n-m)!}}$$
$$\begin{gather}
\begin{pmatrix}
n \\
k
\end{pmatrix}+\begin{pmatrix}
n+1 \\
k
\end{pmatrix}=\begin{pmatrix}
n \\
k+1
\end{pmatrix}\\
1\\
1 \ \ \ 1 \\
1 \ \ \ 2 \ \ \ 1 \\
1 \ \ \ 3 \ \ \ 3 \ \ \ 1 \\
1 \ \ \ 4\ \ \ 6 \ \ \ 4 \ \ \ 1
\end{gather}$$
4. Имеются элементы n типов
$$\begin{gather}
k_{1}+k_{2}+\dots+k_{n}=m\\
P(k_{1},k_{2},\dots,k_{n})={\frac{k_{1}+k_{2}+\ldots+k_{n}}{k_{1}\cdot k_{2}\cdot\ldots\cdot k_{n}}}
\end{gather}$$
5. Размещения с повторениями
$$\overline{A_{n}^m}=n^m$$
6. Сочетания с повторениями
$$\overline{C_{n}^{m}}=C_{n+m-1}^{n-1}=C_{n+m-1}^m={\frac{(n+m-1)!}{m!(n-1)!}}$$
Пример:
$$\begin{gather}
\text{Имеется n неразличимых шаров, m различимых ящиков,  так чтобы все ящики были заняты}\\
n\leq m \\
\cdot\cdot\cdot|\cdot\cdot|\cdot|\cdot\cdot\cdot\cdot|\cdot\\
\text{n-1 граница разделит точки на n частей}
\end{gather}$$
Модель геометрической вероятности
$$\begin{gather}
\Omega \ - \ \text{Измеримая геометрическая фигура} \to \exists \ \text{mes}(\Omega)\\
\mathcal{A} \ - \ \text{измеримые подмножества} \\
P(A \in \mathcal{A})={\frac{\text{mes}(A)}{\text{mes}(\Omega)}}
\end{gather}$$
Основные теоремы вероятности
1. $A\subset B \Rightarrow P(B\backslash A)=P(B)-P(A)$ (См 3 аксиому и определение разности)
2. $A\subset B\Rightarrow P(A)\leq P(B)$ - P - это мера
3. $\forall   A \ \ 0\leq P(A) \leq 1$  т.к. $A\subset \Omega\Rightarrow P(A)\leq P(\Omega)=1$
4. Теорема сложения: $P(A+B)=P(A)+P(B)-P(A\cdot B)$ - это мера
5. $P(\overline{A})=1-P(A)$  (см 1 св-во)
6. Теорема непрерывности: $B_{n+1}\subset B_{n}\subset\dots \subset B_{2}\subset B_{1} \wedge \cap_{i}B_{i}=\varnothing \Rightarrow \exists \lim_{ n \to \infty }P(B_{n})=0$ - это мера
##### 20/02/2025
Примеры вероятностных моделей.
Класс модель $\to$ Гипергеометрическая модель
$(\Omega, \mathcal{A}, P)$ 
$\Omega$ - конечное множество
$\mathcal{A}$ - все подмножества
$P(A)=\frac{\lvert A \rvert}{\lvert \Omega \rvert}$
$n_1$ - предметов 1 типа
$n_2$ - предметов 2 типа
Выберем $m$ прдеметов без возвращения $m\leq n_{1}, m\leq n_{2}$
$A_{k}$ - среди вынутых предметов $k\ -1$-го типа, $(m-k)\ -$ 2-го типа.
$\lvert A_{k} \rvert = C_{n_{1}}^k-C_{n_{2}}^{m-k}$
$C_{n_{1}}^k$ - выбрано предметов 1 типа
$$P(A_{k})=\frac{C_{n_{1}}^kC_{n_{2}}^{m-k}}{C_{n_{1}+n_{2}}^m}$$
Обощение 
Имеются предметы $l$ типов в количетсвах $n_{1},n_{2},\dots,n_{l}$ выберем $m$ предметов.
$$P(A_{k_{1},k_{2},\dots,k_{l}})=\frac{C_{n_{1}}^{k_{1}}C_{n_{2}}^{k_{2}}\dots C_{n_{l}}^{k_{l}}}{C_{n_{1}+n_{2}+\dots+nl}^m}$$

Модель геометрических вероятностей.
Геометрическая вероятность.
$(\Omega, \mathcal{A}, P)$ 
$\Omega$ - измеримое множество
$\mathcal{A}$ - измеримые подмножества
$P(A)=\frac{\mu(A)}{\mu(\Omega)}$
Пример:
Датчик случаёных чисел.
Запускаем его 3 раза. Получаем 3 числа: $x$, $y$, $z \ \in [0,1]$
$P(z>x+y)=?$
$\omega=(x,y,z)\ -$ точка
$\Omega=[0,1]^3$
![[Pasted image 20250220124514.png]]
$$\begin{gather}
P(z>x+y)=\frac{V(A)}{V(\Omega)}=\frac{\frac{1}{6}}{1}=\frac{1}{6}
\end{gather}$$
Парадокс Бертрана
В круге наугод выбирается хорда $x$.  $P(x>R\sqrt{ 3 })=?$
Парадокс в том, что в зависимости от способа выбора случайной хорды, ответ меняется.
Первый способ:
A - произвольная точка.
B - произвольная точка
$x=[A,B]$
$\Omega=[0,2\pi]^2$
$$\begin{gather}
\frac{2\pi}{3}<|x-y|< \frac{4\pi}{3}
\end{gather}$$
![[Pasted image 20250220125234.png]]
$$\begin{gather}
P(x>R\sqrt{ 3 })=\frac{S(C)}{S(\Omega)}=\frac{S(C)}{(2\pi)^2}
\end{gather}$$
Второй способ:
Хорда отождествляется с её серединой
![[Pasted image 20250220125527.png|320]]![[Pasted image 20250220125726.png|320]]
$$\begin{gather}
P(C)=\frac{S(C)}{S(\Omega)}=\frac{\pi\left( \frac{R}{2} \right)^2}{(2\pi)^2}=\frac{1}{4}
\end{gather}$$
Третий способ:
Хорда на диаметре.
Абсолютно непрерывная веротностная модель
$(\Omega, \mathcal{A}, P)$ 
$\Omega=\mathbb{R}$ 
$\mathcal{A}=B$  - борелевская $\sigma$-алгебра
1. $P(A)=\int_{A} p(x)dx$
2. $\int_{-\infty}^{+\infty}p(x)dx=1$
3. цел: $p(x)\geq0$
Пример: гауссовская плотность
$$P_{a.\sigma}(x)=\frac{1}{\sqrt{ 2\pi }\sigma}e^{-\frac{(x-a)^2}{2\sigma^2}}$$
$$\int_{-\infty}^{+\infty}p_{a,\sigma}(x)dx=\begin{vmatrix}
\frac{x-a}{\sqrt{ 2 }\sigma}=y \\
dx=dy\sigma \sqrt{ 2 }
\end{vmatrix}=\int_{-\infty}^{+\infty} \frac{1}{\sqrt{ 8\pi }\sigma}e^{-y^2}\sigma \sqrt{ 2}dy=1$$
$$\int_{b_{1}}^{b_{2}}p_{a,\sigma}(x)dx=\begin{vmatrix}
\frac{x-a}{\sigma}=y \\
dx=\sigma dy
\end{vmatrix}=\frac{1}{\sqrt{ 2\pi }}\int_{\frac{b_{1}-a}{\sigma}}^{\frac{b_{2}-a}{\sigma}}e^{-y^2}dy=\varphi\left( \frac{b_{2}-a}{\sigma} \right)-\varphi\left( \frac{b_{1}-a}{\sigma} \right)$$
Условные вероятности.
$$\begin{gather}
P(A|B)=P_{B}(A)=\frac{P(A\cdot B)}{P(B)}
\end{gather}$$
Пояснение: $n$ опытов, фиксируем события $A$. 
$n_A$ - наступило A
$n_B$ - наступило B
$n_{AB}$ - наступило A и B
$$\begin{gather}
\frac{n_{A}}{n}\approx P(A)\\
\frac{n_{AB}}{n_{B}}\approx P(A|B)\\
\frac{n_{AB}}{n_{B}}=\frac{\frac{n_{AB}}{n}}{\frac{n_{B}}{n}}\approx \frac{P(AB)}{P(B)}
\end{gather}$$
Формула умножения
$$P(AB)=P(A|B)\cdot P(B)$$
Пример
В урне имеется a белых и b чёрных шаров. Вынимаем 2 шара. Вычисляем вероятность того, что оба вынутых шара белые.
$$P(A)=\frac{\#A}{\#\Omega}=\frac{C^2_{a+b}}{C^2_{a+b} }=\frac{a!\cdot2!\cdot(a+b-2)!}{(a-2)!\cdot 2! (a+b)!}=\frac{a(a-1)}{(a+b)(a+b-1)}$$
Событие равносильно следующей совокупности событий:
Достали белый шар, а потом достали второй белый шар
$$P(A)=P(A_{1}A_{2})=P(A_{1})\cdot P(A_{2}|A_{1})=\frac{a}{a+b}\cdot \frac{a-1}{a+b-1}$$
Условное вероятностное пространство
$B, P(B)>0$
$(\Omega,\mathcal{A},P) \to (B, \mathcal{A}_{B},P_{B})$
$\mathcal{A}_{B}=\mathcal{A} \cap B$ - сужение алгебры $\mathcal{A}$ на B.
$$P_{B}(A)=\frac{P(A\cdot B)}{P(B)}\geq0$$
$$P_{B}(B)=1$$
$$\begin{gather}
\begin{matrix}
A_{1}\cap A_{B}=\varnothing \\
P_{B}(A_{1}+A_{2})=\frac{P((A_{1}+A_{2})B)}{P(B)}=\frac{P(A_{1}B+A_{2}B)}{P(B)}=\frac{P(A_{1}B)+P(A_{2}B)}{P(B)}=P_{B}(A_{1})+P_{B}(A_{2})
\end{matrix}
\end{gather}$$
Теорема умножения
$P(A_{1},A_{2},\dots,A_{n})>0\implies$
$$\begin{gather}
P(A_{1},A_{2},\dots,A_{n})=P(A_{1})\cdot P(A_{2}|A_{1})\cdot P(A_{3}|A_{2}A_{1})\cdot\ldots\cdot P(A_{n}|A_{n-1}\dots A_{3}A_{2}A_{1})
\end{gather}$$
Формулы полной вероятности и Байеса
$$\begin{gather}
H_{1},H_{2},\ldots,H_{l} \text{ - полная группа событий} \Leftrightarrow\\
P(H_{i})>0\\
H_{i}\cap H_{j}=\delta_{ij}\\
\sum _{i}H_{i}=\Omega
\end{gather}$$
Теорема о полной вероятности
$$P(A)=\sum _{i=1}^lP(A|H_{i})\cdot P(H_{i})$$
$$\begin{gather}
A=A\Omega=A\sum _{i}H_{i}=\sum _{i}AH_{i}
\end{gather}$$
Пример:
5 белых и 3 черных шара
вынимаем 1 шар и перекладываем в корзину с 2 белыми и 2 черными шарами
Вынимаем шар, какой цвет?
$$\begin{gather}
H_{1} \text{ - переложен белый}\\
H_{2} \text{ - переложен чёрный}\\
P(A)=P(A|H_{1})\cdot P(H_{1})+P(A|H_{2})\cdot P(H_{2})=\frac{3}{5}\cdot \frac{5}{8}+ \frac{2}{5}\cdot \frac{3}{8}=\frac{21}{40}
\end{gather}$$
$$\begin{gather}
\mathcal{H} =\{ H_{i} \} \text{ - полная группа событий}\\
P(H_{i}|A)=\frac{P(A|H_{i})\cdot P(H_{i})}{\sum _{i=1}^lP(A|H_{i})\cdot P(H_{i})}\\
P(H_{i}) \text{ - априорные вероятности}\\
P(H_{i}|A) \text{ - апостериорные вероятности}\\
\end{gather}$$
МК1
$$\begin{gather}
\text{7 белых, 5 черных, 4 красных}\\
7+5+4=16\\
\frac{4}{16}+\frac{12}{16}\cdot \frac{4}{15}=\frac{1}{4}+\frac{1}{4} \cdot \frac{12}{15}< \frac{1}{2}\\
\frac{5}{16}+\frac{11}{16}\cdot \frac{5}{15}=\frac{15}{48}+\frac{11}{48}=\frac{26}{48}> \frac{24}{48}
\end{gather}$$































