Причастие
Неличная форма глагола, которая имеет свойства:
глагола
прилагательного
наречия
Причастие I - ing имеет оттенок действительного залога
Пример: speaking
Причастие II - 3d form (зависит от того, правильный/неправильный глагол). Имеет оттенок страдательного залога
Пример: asked/put
Форма причастия

| Причастие | Действительный залог | Страдательный залог   |
| --------- | -------------------- | --------------------- |
| I         | developing           | being developed       |
| II        | -                    | developed             |
| III       | having developed     | having been developed |
Функции причастия в предложении:
Определение:
The waiting man is in the hall.
The discussed problems are interesting.
Независимый причастный оборот: Сочетание существительного/местоимения с причастием I/II.
The weather being fine we went for a walk.
The car was small the engine being placed under the seat.

После одушевлённого существительного придаточное предложение, а не причастный оборот.

Текст для презентации по английскому:
We know, some modern physics' frameworks are generalizations of theories of the past - for example, classical mechanics is just a special case of the equations of the theory of relativity at speeds negligibly small compared to the speed of light.

As we know, Fermat's principle (also known as principle of least time) states that path taken by a rey between two given points is the path that can be traveled in the least time.

According to modern physics light silmultaneously exhibits properties of particles and waves. This phenomena is named "Wave-particle duality". So, my short presentation is simplified derivation of Fermat's principle from modern axioms. 
Imagine two points: point 1 and point 2. It is known that photon moved from first point two the second. Light is a wave, so its' state depends on time and position in space. 
$f(\varphi_{0}+\omega t+k\vec{r})$
Let's look at 2 paths from 1 to 2: A and B. Light's phase at the point 2 varies, because light will take different time to reach that point. The amplitude of sum of this waves depends on their phases in that point.
$\varphi=\varphi_{0}+\omega t+kx$
then
$d\varphi= kdx-\omega dt$
$d\varphi=(kv-\omega)dt$
$\varphi=\int_{T_{0}}^{T_{1}} (kv-\omega)dt$
From that equation we get that
$\varphi=\frac{1}{h} \int_{T_{1}}^{T_{2}} dS$, where S - is an action. 
If S is minimal than $dS=0$ (it is a nessessary condition for extremum of the function).



См https://kolegite.com/EE_library/books_and_lectures/%D0%A4%D0%B8%D0%B7%D0%B8%D0%BA%D0%B0/The%20Feynman%20Lectures%20on%20Physics%2C%20Vol.%20I%2CII%2CIII%20The%20New%20Millennium%20Edition%20by%20Richard%20P.%20Feynman%20%28z-lib.org%29.pdf
страница 466

**Fermat's principle**, also known as the **principle of least time**, is the link between [ray optics](https://en.wikipedia.org/wiki/Geometrical_optics "Geometrical optics") and [wave optics](https://en.wikipedia.org/wiki/Physical_optics "Physical optics"). Fermat's principle states that the path taken by a [ray](https://en.wikipedia.org/wiki/Ray_\(optics\) "Ray (optics)") between two given points is the path that can be traveled in the least time.


As we know, Snell's law (also known as law of refraction) states which states that, for a given pair of media, the ratio of sines of angle of incidence and angle of refraction is equal to the refractive index of the second medium with regard to the first

**Snell's law** (also known as the **Snell–Descartes law**, the **ibn-Sahl** **law**,[[1]](https://en.wikipedia.org/wiki/Snell%27s_law#cite_note-1) and the **law of refraction**) is a [formula](https://en.wikipedia.org/wiki/Formula "Formula") used to describe the relationship between the [angles of incidence](https://en.wikipedia.org/wiki/Angle_of_incidence_\(optics\) "Angle of incidence (optics)") and [refraction](https://en.wikipedia.org/wiki/Refraction "Refraction"), when referring to [light](https://en.wikipedia.org/wiki/Light "Light") or other [waves](https://en.wikipedia.org/wiki/Wave "Wave") passing through a boundary between two different [isotropic](https://en.wikipedia.org/wiki/Isotropic "Isotropic") [media](https://en.wikipedia.org/wiki/Medium_\(optics\) "Medium (optics)"), such as water, glass, or air. In optics, the law is used in [ray tracing](https://en.wikipedia.org/wiki/Ray_tracing_\(physics\) "Ray tracing (physics)") to compute the angles of incidence or refraction, and in experimental optics to find the [refractive index](https://en.wikipedia.org/wiki/Refractive_index "Refractive index") of a material. The law is also satisfied in [meta-materials](https://en.wikipedia.org/wiki/Metamaterials#Negative_refractive_index "Metamaterials"), which allow light to be bent "backward" at a negative angle of refraction with a [negative refractive index](https://en.wikipedia.org/wiki/Refractive_index#Negative_refractive_index "Refractive index").

The law states that, for a given pair of media, the ratio of the sines of [angle of incidence](https://en.wikipedia.org/wiki/Angle_of_incidence_\(optics\) "Angle of incidence (optics)") (θ1)![{\displaystyle \left(\theta _{1}\right)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c963fa526860351e03f1647bb5c99abc22e8583f) a![{1}\right)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c963fa526860351e03f1647bb5c99abc22e8583f)nd angle of refraction (θ2)![{\displaystyle \left(\theta _{2}\right)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/5f5f464a42bcc5f4817d0c574eefc7410cee5866) is equal to the refractive index of the second medium with regard to the first (n21![{\displaystyle n_{21}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/5643f53447ac0f083e231a91d70839b11fe5293c)) which is equal to the ratio of the [refractive indices](https://en.wikipedia.org/wiki/Refractive_indices "Refractive indices") (n2n1)![{\displaystyle \left({\tfrac {n_{2}}{n_{1}}}\right)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/9c11a5c90b6068c47db674266056adb2598c25c7) of the two media, or equivalently, to the ratio of the [phase velocities](https://en.wikipedia.org/wiki/Phase_velocities "Phase velocities") (v1v2)![{\displaystyle \left({\tfrac {v_{1}}{v_{2}}}\right)}](https://wikimedia.org/api/rest_v1/media/math/render/svg/6c96d58118108d9a2d473fbe263d8a01e18e1d56) in the two media.


________________
This content was downloaded from IP address 89.113.152.11 on 22/04/2025 at 11:39
Electromagnetism as a purely geometric theory
1 Introduction
The history of physics may be viewed as a slow progression from particle-oriented concepts towards
wave-oriented concepts. A thousand years ago, a discussion of “fields” and “waves” would have been
met with blank stares. Only the concept of matter particles existed at the time, with direct mechanical
interactions among them. Waves were only observed on the surface of water, and were neither understood
mathematically nor were they thought to be related to anything else. Scientists of the middle ages thought
of light as a stream of small “light balls”. Later, in particular, Isaac Newton (1642-1726) advocated the
particle view of light, whereas Christiaan Huygens (1629-1695) advocated the wave-picture of light.
Earlier, the philosopher and inventor of analytic geometry, Ren´e Descartes (1596-1650) had advocated
a wave theory of light as well. During the 19th century, the flying “light balls” model was replaced by
a “waves of aether balls” model, which in turn was replaced in the 1920s by the “waves of electric and
magnetic fields” model. By now, all mechanical and chemical forces are also described as being exerted
by such electromagnetic waves. Approximately one hundred years ago, the notion that elementary matter
particles might also be quantum mechanical waves started to gain acceptance. In this sense, our work
fits into the historic trend, and represents a next step in the understanding of wave-oriented concepts.
A key milestone in the development of wave oriented concepts was the recognition during the early
20th century that gravity is essentially not a force, but a manifestation of spacetime curvature, due to
Albert Einstein in 1915. As the Earth orbits the Sun, it moves along a straight trajectory of its local
spacetime metric. The curvature of spacetime metric around the Sun is the origin of the circular Earth
orbit; with the proper accounting of this spacetime curvature there is no further need to apply any
additional gravitational force. It is a logical next question to ask whether electromagnetic forces can
be also accounted for by spacetime curvature. The present work focuses on this question, and we find
that the geometric accounting of electromagnetic fields and charges are inseparable. In other words, the
proper accounting of spacetime curvature yields not only electromagnetic forces, but also charges. Thismeans, that currents and charges are not external sources, but they can be endogenized to be immanent
properties of the spacetime metric, along with the electromagnetic field.
In [1], it was shown that the (singular) metric composed of the tensor product of the electromagnetic
four-potential with itself yields Maxwell’s equations, if we demand Ricci-flatness from the metric. On
the other hand, in the paper [2], the Stueckelberg wave equation, see [3], and the Schr¨odinger equation
were derived from a stochastic optimal control scheme on a Minkowskian spacetime, when it was assumed
that the test particle is affected by Brownian noise on the spacetime manifold. Furthermore, in [4] the
Heisenberg uncertainty principle was deduced from such spacetime optimal control approach. In [2], the
Stueckelberg and Schr¨odinger equations can be derived as the linearized Hamilton-Jacobi-Bellman equations,
assuming that the value function is locally smooth and thus linear. Local linear approximation is
indeed appropriate on Planck scales.
The above-mentioned results could indicate, that quantum mechanics is an instrumental theory in the
sense that it describes correctly the universe at small scales. Nevertheless, it could be that for example
random movements of electrons could result from something more fundamental described in relativistic
electrodynamics. For example, a stochastic metric could lead to stochastic forces, which may be
phenomenologically modeled using the spacetime diffusion approach. The quantum mechanical model
presented in [2] starts from an assumption that there is a potential defined on the Minkowski spacetime
and the test particle undergoes Brownian motion with a controlled drift. Minimizing the expected
canonical action then leads to the equations of quantum mechanics when we assume a locally linear value
function. The model thus assumes exogenous noise structure for the test particle. The dual approach is
that we assume that the spacetime itself is fluctuating at Planck scales [5, 6, 7].
If electrodynamic force, i.e. the Lorentz force could be related directly to metrics, it directly leads
to the explanation of the Zitterbewegung phenomenon and quantum mechanical waves as well. This
result shall be derived in sections 5 and 6.
For the above assumptions to work, we would need to be able to establish electrodynamics as a purely
geometrical theory. In other words, the electromagnetic field should be derived purely and solely from
the properties of the metric tensor. As for the Lorentz force, the force on charges should be derived as
some geometrical property as well. It turns out that these requirements can be fulfilled. Electromagnetic
field obeys a requirement, where in general nature wants to minimize the deviation of Weyl geometry
from pseudo-Riemannian geometry. On the other hand, the Lorentz force law is the geodesic equation in
disguise.
The covariant divergence of the electromagnetic four-potential was assumed to be related to the charge
density in [1]. The presence of an electric charge however would then violate the condition of metric
compatibility of the metric and thus we must have a more general connection. The property of torsionlessness
can be retained, but metric compatibility must be replaced with a weaker assumption of
semimetricity. This gives us exactly the Weyl geometry discussed for example in [8]. Hermann Weyl
(1885-1955) introduced this geometry in 1918, when he was trying to combine gravity with electromagnetism
[9]. According to Erhard Scholz, in [10] he says ”Weyl’s original scale geometry of 1918 (“purely
infinitesimal geometry”) was withdrawn by its author from physical theorizing in the early 1920s. It
made a surprising comeback, however, in the last third of the 20th century in several different contexts:
scalar-tensor theories of gravity, foundations of spacetime theories, foundations of quantum mechanics,
elementary particle physics, and cosmology. It seems that Weyl geometry continues to offer an open
window for research on the foundations of physics even after the turn into the new millennium.”. The
present approach gives a different identification for the 1-form as compared to the original Weyl’s approach.
Weyl geometry and its possible conformity with existing physics is discussed for example in [11].
It has been the tradition in general relativity that the spacetime is modeled using pseudo-Riemannian geometry.
In particular, this assumption implies that the covariant derivative of the metric tensor vanishes
everywhere. However, there are extensions to the pseudo-Riemannian geometry where this fundamental
assumption is omitted. We consider Weyl geometry, where the covariant derivative ∇σ of the metric
tensor gμν is of a special form
__________________________________________
Materials and Material Science (11A 47)
1 Ancient MaMS:
machines, structures, devices, and other products
the Stone Age, the Bronze Age, the Iron Age, etc
metals, polymers, ceramics, and composites.
2 MaMS influence us:
medicine and health, information and communication, national security and space, transportation, textiles, personal hygiene, agriculture, food science and the environmental protection.
3 MaMS in present (20-21 century):
$110 million, 200 kilowatts - 2 kW per year, 14 m tall, 3.5 billion people
metallic alloys, silica and carbon materials,
4 Advances in MaMS:
the metamaterials used in carbon fiber composites for lighter-weight vehicles, advanced alloys for more durable jet engines, and biomaterials to replace human joints
graphene, carbon nanotubes, composites, thin metallic- and semiconductor-based films
5 Sum it up
_______________________
Thanks for clarifying! I’ll create a combined summary and analysis focusing specifically on the influence of artificial intelligence on the job market, based on the 'Future of Jobs Report 2025'. I’ll prioritize real-world data and examples where available. I'll let you know when the full write-up is ready for your review.

# Future of Jobs 2025 – AI and the Labour Market

**Technological Drivers:** The report identifies **digital expansion and AI** as top drivers of change. Broadening digital access is “the most transformative trend – both across technology-related trends and overall – with 60% of employers expecting it to transform their business by 2030” ([WEF_Future_of_Jobs_Report_2025.pdf](file://xn--file-8g5geluqfauzduwuuygzrx%23:~:text=%20broadening%20digital%20access%20is,these%20trends%20are%20expected%20to-ww95e/)). Advancements in **AI and data processing (86% of employers), robotics/automation (58%) and clean energy (41%)** are also cited as highly transformative ([WEF_Future_of_Jobs_Report_2025.pdf](file://xn--file-8g5geluqfauzduwuuygzrx%23:~:text=%20broadening%20digital%20access%20is,these%20trends%20are%20expected%20to-ww95e/)). These shifts will have _divergent effects_ on jobs: they will create both the fastest-growing and fastest-declining roles, and sharply raise demand for technical skills. In fact, roles like **AI/Machine Learning Specialists and Big Data Specialists** are among those with the largest projected demand, and skills such as **AI, big data, networks, cybersecurity and technological literacy** are expected to grow fastest ([WEF_Future_of_Jobs_Report_2025.pdf](file://file-8g5geluqfauzduwuuygzrx%23:~:text=big%20data%20specialists%20and%20ai,are%20leading%20the%20list%20of/)) ([WEF_Future_of_Jobs_Report_2025.pdf](file://file-8g5geluqfauzduwuuygzrx%23:~:text=have%20a%20divergent%20effect%20on,growing%20skills/)).

**Employment Trends – Job Creation vs Displacement:** The survey projects that by 2030 about **22% of current jobs** will be affected by these trends. Specifically, employers expect **14% of today’s jobs (≈170 million jobs)** to be created by new technologies, while **8% (≈92 million jobs)** will be displaced by automation and other shifts ([WEF_Future_of_Jobs_Report_2025.pdf](file://file-8g5geluqfauzduwuuygzrx%23:~:text=of%2022,of/)). The net effect is roughly **78 million new jobs** globally (+7% net growth) by 2030 ([WEF_Future_of_Jobs_Report_2025.pdf](file://file-8g5geluqfauzduwuuygzrx%23:~:text=of%2022,of/)). These figures illustrate AI’s **positive impact** on total employment (net job growth) but also underscore a large-scale displacement of workers.

- **Growing occupations:** Technology-intensive jobs lead growth. For example, **Frontline and care roles** (e.g. farmworkers, delivery drivers, construction workers, nurses and teachers) are expected to grow in volume ([WEF_Future_of_Jobs_Report_2025.pdf](file://xn--file-8g5geluqfauzduwuuygzrx%23:~:text=%20frontline%20job%20roles%20are,next%20five%20years,%20alongside%20education-qp97e/)), and **tech jobs** – especially those involving AI, machine learning, big data and software development – are fastest-growing in percentage terms ([WEF_Future_of_Jobs_Report_2025.pdf](file://xn--file-8g5geluqfauzduwuuygzrx%23:~:text=%20technology,growing%20roles-hz26b/)). Green-tech roles (e.g. electric/autonomous vehicle specialists, renewable energy engineers) also feature strongly in the growth list ([WEF_Future_of_Jobs_Report_2025.pdf](file://xn--file-8g5geluqfauzduwuuygzrx%23:~:text=%20technology,growing%20roles-hz26b/)).
    
- **Declining occupations:** Routine clerical and administrative jobs are cited as most at risk. For instance, **Cashiers, Ticket Clerks, Data Entry Clerks, Postal Workers and Bank Tellers** are among roles expected to see the largest declines ([WEF_Future_of_Jobs_Report_2025.pdf](file://xn--file-8g5geluqfauzduwuuygzrx%23:~:text=%20clerical%20and%20secretarial%20workers,tellers%20and%20data%20entry%20clerks-mw29e/)). This reflects automation of routine tasks.
    

**Skills Demand and Workforce Shifts:** AI’s rise is driving huge shifts in skill demand. Employers report that about **39% of workers’ current skills** will be transformed or outdated by 2030 ([WEF_Future_of_Jobs_Report_2025.pdf](file://file-8g5geluqfauzduwuuygzrx%23:~:text=on%20average,%20workers%20can%20expect,having%20completed%20training,%20reskilling/)). This “skill instability” is slightly lower than in past reports (39% vs 44% in 2023), likely reflecting that more workers (50% vs 41%) have already undergone reskilling or upskilling ([WEF_Future_of_Jobs_Report_2025.pdf](file://file-8g5geluqfauzduwuuygzrx%23:~:text=on%20average,%20workers%20can%20expect,having%20completed%20training,%20reskilling/)). Top skills in demand are heavily tech‑oriented: **AI and big data skills** top the fastest-growing list ([WEF_Future_of_Jobs_Report_2025.pdf](file://file-8g5geluqfauzduwuuygzrx%23:~:text=have%20a%20divergent%20effect%20on,growing%20skills/)), alongside networks, cybersecurity and general tech literacy ([WEF_Future_of_Jobs_Report_2025.pdf](file://file-8g5geluqfauzduwuuygzrx%23:~:text=have%20a%20divergent%20effect%20on,growing%20skills/)). At the same time, core “human” skills remain critical: _analytical thinking_ is now the most sought-after core skill (70% of employers consider it essential) ([WEF_Future_of_Jobs_Report_2025.pdf](file://xn--file-8g5geluqfauzduwuuygzrx%23:~:text=%20analytical%20thinking%20remains%20the,is%20followed%20by%20resilience,%20flexibility-5o54f/)). Other soft skills like creativity, resilience and flexibility also rise in importance.

**Quantitative Highlights:**

- **Jobs:** +170 million created vs –92 million lost by 2030 (net +78 million) ([WEF_Future_of_Jobs_Report_2025.pdf](file://file-8g5geluqfauzduwuuygzrx%23:~:text=of%2022,of/)).
    
- **Growing Roles:** Big Data, Fintech, AI/ML specialists, software developers, EV/Autonomous vehicle engineers, etc. ([WEF_Future_of_Jobs_Report_2025.pdf](file://xn--file-8g5geluqfauzduwuuygzrx%23:~:text=%20technology,growing%20roles-hz26b/)) ([WEF_Future_of_Jobs_Report_2025.pdf](file://file-8g5geluqfauzduwuuygzrx%23:~:text=big%20data%20specialists%20and%20ai,are%20leading%20the%20list%20of/)).
    
- **Declining Roles:** Cashiers, secretaries, data-entry, postal clerks, bank tellers ([WEF_Future_of_Jobs_Report_2025.pdf](file://xn--file-8g5geluqfauzduwuuygzrx%23:~:text=%20clerical%20and%20secretarial%20workers,tellers%20and%20data%20entry%20clerks-mw29e/)).
    
- **Skills Changes:** 39% of skills to shift; 50% of workers trained (up from 41%) ([WEF_Future_of_Jobs_Report_2025.pdf](file://file-8g5geluqfauzduwuuygzrx%23:~:text=on%20average,%20workers%20can%20expect,having%20completed%20training,%20reskilling/)). Top growing skills: AI & big data ([WEF_Future_of_Jobs_Report_2025.pdf](file://file-8g5geluqfauzduwuuygzrx%23:~:text=have%20a%20divergent%20effect%20on,growing%20skills/)) ([WEF_Future_of_Jobs_Report_2025.pdf](file://xn--file-8g5geluqfauzduwuuygzrx%23:~:text=%20ai%20and%20big%20data,as%20well%20as%20technology%20literacy-jc78d/)); 79% of firms expect _analytical thinking_ use to increase ([WEF_Future_of_Jobs_Report_2025.pdf](file://file-8g5geluqfauzduwuuygzrx%23:~:text=skill%20gaps%20are%20categorically%20considered,to%20reduce%20staff%20as%20their/)).
    

**Implications:** For **workers**, the message is clear: continuous learning is vital. As one analysis notes, “if the world’s workforce was made up of 100 people, 59 would need training by 2030” to meet new demands ([WEF_Future_of_Jobs_Report_2025.pdf](file://file-8g5geluqfauzduwuuygzrx%23:~:text=given%20these%20evolving%20skill%20demands,,reskilling%20or%20upkskilling%20needed,%20leaving/)). Workers should focus on tech-savvy, creative and adaptive skills (e.g. analytical problem‑solving, AI/data literacy). For **businesses**, the report recommends aggressive reskilling: a large majority (85%) of employers plan to prioritize upskilling their workforce ([WEF_Future_of_Jobs_Report_2025.pdf](file://file-8g5geluqfauzduwuuygzrx%23:~:text=skill%20gaps%20are%20categorically%20considered,to%20reduce%20staff%20as%20their/)), and 70% expect to hire new talent for emerging roles. Half of employers even plan to redeploy existing staff from declining roles into new growth areas ([WEF_Future_of_Jobs_Report_2025.pdf](file://file-8g5geluqfauzduwuuygzrx%23:~:text=skill%20gaps%20are%20categorically%20considered,to%20reduce%20staff%20as%20their/)). Finally, for **policymakers and educators**, the findings underscore the need for supportive policies (e.g. education, training incentives, and transition programs) to manage this transition. Over 60% of employers see skill gaps as a major barrier to transformation ([WEF_Future_of_Jobs_Report_2025.pdf](file://file-8g5geluqfauzduwuuygzrx%23:~:text=skill%20gaps%20are%20categorically%20considered,to%20reduce%20staff%20as%20their/)), so addressing those gaps will be critical to harnessing AI’s benefits while reducing displacement risks.

**Sources:** Data and projections are drawn directly from the _Future of Jobs Report 2025_ ([WEF_Future_of_Jobs_Report_2025.pdf](file://xn--file-8g5geluqfauzduwuuygzrx%23:~:text=%20broadening%20digital%20access%20is,these%20trends%20are%20expected%20to-ww95e/)) ([WEF_Future_of_Jobs_Report_2025.pdf](file://file-8g5geluqfauzduwuuygzrx%23:~:text=of%2022,of/)). Each statistic above is explicitly cited from the WEF report.
_________________
to require, to repair damage.

What’s the Big Idea?
(1) With the active development of robotics, we are increasingly seeing the emergence of more user friendly home robots. Whether it will be something like the ASIMO robot from Honda designed to help and communicate with people, or we are talking about machines that will replace people in some work positions (for example, waiters, reception workers), one thing is clear: the development of robotics will not stop. Relatively soon, in addition to televisions, computers, washing machines and microwaves, a small army of robot personal assistants will become an integral part of almost every home on the planet.
(2) Developers at Samsung are trying to one-up Google Glass, the technology that delivers the Internet via a pair of eyeglasses, by creating contact lenses capable of displaying the same electronic information. Engineers have mounted a light-emitting diode on an off-the-shelf soft contact lens, using a material the researchers developed: a transparent, highly conductive, and stretchy mix of graphene and silver nanowires. In addition to displaying the Internet, and a host of accompanying applications, electronic contact lenses could prove even more promising in the medical field. Such lenses are currently being developed in order to filter light to compensate for vision problems. And while current efforts are limited to displaying one pixel on a given lens, it is a necessary first step toward making more complex versions in the future.
(3) The Norwegian coast may be beautiful but with more than a thousand fjords cutting into it, getting from one place to another often requires lengthy journeys. Norway has an ambitious plan to solve the problem by building the world’s first floating submerged tunnel system about 30 meters (100ft) underwater. The first-of-its kind structure will be made up of two 1,200 meter (4,000ft) curved concrete tubes, floating up to 30 meters (100ft) below the surface. The tubes will be supported by pontoons on the surface and kept stable with connecting trusses. For extra stability, the construction might be bolted to the bedrock as well. On the surface, there would be wide gaps between the pontoons to allow ferries to pass through. Having this connection means that people there do not have to wait for a helicopter to go to the hospital. 
(4) Scientists say that a new kind of robot can reproduce, i. e. create ‘baby’ robots. This is an example of science fiction becoming science fact. The scientists created the world's first "living" robots from the stem cells of an African frog. Its scientific name – "xenopus laevis" – gave the xenobot its name. The xenobots are less than a millimetre wide. They can move, work together in groups and self-heal. Although they are not what we imagine robots to be, scientists say they are technically robots. They are a machine-animal hybrid. The scientists say xenobots are "an entirely new life-form". The xenobots are very early technology. However, they could change science, medicine, technology and the way we live. They could carry out tasks inside our body to repair damage to organs. They could also help the environment by attacking micro-plastics in our oceans, or by cleaning up oil spills. Despite the possible benefits, some people are worried about robots that can reproduce.
(5) Roads of the future could be lit by glowing trees instead of streetlamps, thanks to a breakthrough in creating bioluminescent plants. Experts injected specialised nanoparticles into the leaves of a watercress plant, which caused it to give off a dim light for nearly four hours. To create their glowing plants, engineers turned to an enzyme called “luciferase”. Luciferases make up a class of oxidative enzymes found in several species that enable them to be bioluminescent, or emit light. For example, fireflies are able to emit light via a chemical reaction with the luciferase enzyme. The reaction is highly efficient, meaning nearly all the energy put into the reaction is rapidly converted to light. Researchers believe with further tweaking, the technology could also be used to provide lights bright enough to illuminate a workspace or even an entire street, as well as low-intensity indoor lighting. Lighting accounts for around 20 per cent of worldwide energy consumption, so using bioluminescent plants for lighting will represent a significant cut to CO2 emissions.

_________
A Case against the GO TO Statement.

> by Edsger Wybe Dijkstra
> Technological University  
> Eindhoven, The Netherlands

Since a number of years I am familiar with the observation that the quality of programmers is a decreasing function of the density of **go to** statements in the programs they produce. Later I discovered why the use of the **go to** statement has such disastrous effects and did I become convinced that the go to statement should be abolished from all "higher level" programming languages (i.e. everything except —perhaps— plain machine code). At that time I did not attach too much importance to this discovery; I now submit my considerations for publication because in very recent discussions in which the subject turned up, I have been urged to do so.

My first remark is that, although the programmer’s activity ends when he has constructed a correct program, the process taking place under control of his program is the true subject matter of his activity, for it is this process that has to effectuate the desired effect, it is this process that in its dynamic behaviour has to satisfy the desired specifications. Yet, once the program has been made, the “making” of the corresponding process is delegated to the machine.

My second remark is that our intellectual powers are rather geared to master static relations and that our powers to visualize processes evolving in time are relatively poorly developed. For that reason we should do (as wise programmers aware of our limitations) our utmost best to shorten the conceptual gap between the static program and the dynamic process, to make the correspondence between the program (spread out in text space) and the process (spread out in time) as trivial as possible.

Let us now consider how we can characterize the progress of a process. (You may think about this question in a very concrete manner: suppose that a process, considered as a time succession of actions, is stopped after an arbitrary action, what data do we have to fix in order that we can redo the process until that very same point?) If the program text is a pure concatenation of, say, assignment statements (for the purpose of this discussion regarded as the descriptions of single actions) it is sufficient to point in the program text to a point between two successive action descriptions. (In the absence of **go to** statements I can permit myself the syntactic ambiguity in the last three words of the previous sentence: if we parse them as "successive (action descriptions)" we mean successive in text space, if we parse as "(successive action) descriptions" we mean successive in time.) Let us call such a pointer to a suitable place in the text a "textual index".

When we include conditional clauses (**if** B **then** A), alternative clauses (**if** B **then** A1 **else** A2), choice clauses as introduced by Charles.Antony.Richard.Hoare (**case**\[i] **of** (A1, A2,.....,An)) or conditional expressions as introduced by John. McCarthy (B1 → E1, B2 → E2,....., Bn → En), the fact remains that the progress of the process remains characterized by a single textual index.

As soon as we include in our language procedures we must admit that a single textual index is no longer sufficient: in the case that a textual index points to the interior of a procedure body the dynamic progress is only characterized when we also give to which call of the procedure we refer. With the inclusion of procedures we can characterize the progress of the process via a sequence of textual indices, the length of this sequence being equal to the dynamic depth of procedure calling.

Let us now consider repetition clauses (like, **while** B **repeat** A or **repeat** A **until** B). Logically speaking, such clauses are now superfluous, because we can express repetition with the aid of recursive procedures. For reasons of realism I don't wish to exclude them: on the one hand repetition clauses can be implemented quite comfortably with present day finite equipment, on the other hand the reasoning pattern known as “induction” makes us well equipped to retain our intellectual grasp on the processes generated by repetition clauses. With the inclusion of the repetition clauses textual indices are no longer sufficient to describe the dynamic progress of the process. With each entry into a repetition clauses, however, we can associate a so-called “dynamic index”, inexorably counting the ordinal number of the corresponding current repetition. As repetition clauses (just as procedure calls) may be applied nestedly, we find that now the progress of the process can always be uniquely characterized by a (mixed) sequence of textual and/or dynamic indices.

The main point is that the values of these indices are outside programmer's control: they are generated (either by the write up of his program or by the dynamic evolution of the process) whether he wishes or not. They provide independent coordinates in which to describe the progress of the process.

Why do we need such independent coordinates? The reason is—and this seems to be inherent to sequential processes—that we can interpret the value of a variable only with respect to the progress of the process. If we wish to count the number, n say, of people in an initially empty room, we can achieve this by increasing n by 1 whenever we see someone entering the room; in the in-between moment that we have observed someone entering the room but have not yet performed the subsequent increase of n, its value equals the number of people in the room minus one!

The unbridled use of the **go to** statement has as an immediate consequence that it becomes terribly hard to find a meaningful set of coordinates in which to describe the process progress. Usually, people take into account as well the values of some well chosen variables, but this is out of the question because it is relative to the progress that the meaning of these values is to be understood! With the **go to** statement one can, of course, still describe the progress uniquely by a counter counting the number of actions performed since program start (viz. a kind of normalized clock). The difficulty is that such a coordinate, although unique, is utterly unhelpful: in such a coordinate system it becomes an extremely complicated affair to define all those points of progress where, say, n equals the number of persons in the room minus one!

The **go to** statement as it stands is just too primitive, it is too much an invitation to make a mess of one's program. One can regard and appreciate the clauses considered as bridling its use. I do not claim that the clauses mentioned are exhaustive in the sense that they will satisfy all needs; but whatever clauses are suggested (e.g. abortion clauses) they should satisfy the requirement that a programmer independent coordinate system can be maintained to describe the process in a helpful and manageable way.

It is hard to end this article with a fair acknowledgement: am I to judge by whom my thinking has been influenced? It is fairly obvious that I am not uninfluenced by Peter Landin and Christopher Strachey, and that I do not regret their influence upon me. Finally I should like to record (as I remember it quite distinctly) how Heinz Zemanek at the pre-ALGOL meeting in early 1959 in Copenhagen quite explicitly expressed his doubts whether the **go to** statement should be treated on equal syntactic footing with the assignment statement. To a modest extent I blame myself for not having then drawn the consequences of his remark.

The remark about the undesirability of the **go to** statement is far from new. I remember having read the explicit recommendation to restrict the use of the **go to** statement to alarm exits, but I have not been able to trace it; presumably, it has been made by C.A.R. Hoare. In [1, Sec. 3.2.1] Wirth and Hoare together make a remark in the same direction in motivating the case construction: “Like the conditional, it mirrors the dynamic structure of a program more clearly than **go to** statements and switches, and it eliminates the need for introducing a large number of labels in the program.”

In [2] Guiseppe [sic] Jacopini seems to have proved the (logical) superfluousness of the **go to** statement. The exercise to translate an arbitrary flow diagram more or less mechanically into a jumpless one, however, is not to be recommended. Then the resulting flow diagram cannot be expected to be more transparent than the original one.
